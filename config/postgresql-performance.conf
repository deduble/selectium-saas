# PostgreSQL Performance Configuration for Selextract Cloud
# Optimized for high-concurrency workloads and efficient resource utilization

# -----------------------------
# CONNECTION AND AUTHENTICATION
# -----------------------------

# Connection settings
max_connections = 200                    # Increased from default 100
superuser_reserved_connections = 3

# Authentication
authentication_timeout = 1min
password_encryption = scram-sha-256

# SSL
ssl = on
ssl_ciphers = 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256'
ssl_prefer_server_ciphers = on

# -----------------------------
# RESOURCE USAGE (except WAL)
# -----------------------------

# Memory settings (adjust based on available RAM)
shared_buffers = 8GB                     # 25% of total RAM for dedicated server
huge_pages = try                         # Enable transparent huge pages
temp_buffers = 8MB                       # Temporary table buffer size
work_mem = 4MB                          # Working memory for sorts/hashes
hash_mem_multiplier = 1.0               # Hash table memory multiplier
maintenance_work_mem = 1GB              # Memory for maintenance operations
autovacuum_work_mem = -1                # Use maintenance_work_mem
max_stack_depth = 2MB

# Background writer
bgwriter_delay = 200ms                  # Background writer sleep time
bgwriter_lru_maxpages = 100             # LRU pages written per round
bgwriter_lru_multiplier = 2.0           # Multiple of avg buffer usage
bgwriter_flush_after = 512kB           # Flush dirty buffers after this amount

# Asynchronous behavior
effective_io_concurrency = 200          # Concurrent I/O operations
max_worker_processes = 8                # Maximum background processes
max_parallel_workers_per_gather = 2     # Parallel workers per Gather node
max_parallel_maintenance_workers = 2    # Parallel maintenance workers
max_parallel_workers = 8                # Maximum parallel workers total

# -----------------------------
# WRITE AHEAD LOG (WAL)
# -----------------------------

# WAL settings
wal_level = replica                      # Minimal WAL level for replication
fsync = on                              # Force synchronization to disk
synchronous_commit = on                 # Synchronous commit mode
wal_sync_method = fdatasync             # Method for forcing WAL updates
full_page_writes = on                   # Write full pages to WAL
wal_compression = on                    # Compress WAL records
wal_log_hints = off                     # Log hint bit updates
wal_buffers = 16MB                      # WAL buffer size
wal_writer_delay = 200ms                # WAL writer sleep time
wal_writer_flush_after = 1MB            # WAL writer flush threshold

# Checkpoints
checkpoint_timeout = 5min               # Maximum checkpoint interval
checkpoint_completion_target = 0.9      # Checkpoint completion target
checkpoint_flush_after = 256kB          # Flush after this amount
checkpoint_warning = 30s                # Warn if checkpoints happen too frequently

# WAL archiving (for backups)
archive_mode = on
archive_command = '/usr/local/bin/archive_wal.sh %p %f'
archive_timeout = 1800s                 # Archive timeout (30 minutes)

# -----------------------------
# REPLICATION
# -----------------------------

# Master server settings
max_wal_senders = 10                    # Maximum WAL sender processes
max_replication_slots = 10              # Maximum replication slots
track_commit_timestamp = off            # Track commit timestamps
hot_standby = on                        # Allow queries on standby

# -----------------------------
# QUERY TUNING
# -----------------------------

# Planner settings
enable_bitmapscan = on
enable_hashagg = on
enable_hashjoin = on
enable_indexscan = on
enable_indexonlyscan = on
enable_material = on
enable_mergejoin = on
enable_nestloop = on
enable_parallel_append = on
enable_parallel_hash = on
enable_partition_pruning = on
enable_partitionwise_join = on
enable_partitionwise_aggregate = on
enable_seqscan = on
enable_sort = on
enable_tidscan = on

# Planner cost constants (tuned for SSD storage)
seq_page_cost = 1.0                     # Sequential page cost
random_page_cost = 1.1                  # Random page cost (low for SSD)
cpu_tuple_cost = 0.01                   # CPU cost per tuple
cpu_index_tuple_cost = 0.005            # CPU cost per index tuple
cpu_operator_cost = 0.0025              # CPU cost per operator
parallel_tuple_cost = 0.1               # CPU cost per tuple for parallel query
parallel_setup_cost = 1000.0            # Cost of starting parallel workers
jit_above_cost = 100000                 # JIT compilation threshold
jit_inline_above_cost = 500000          # JIT inlining threshold
jit_optimize_above_cost = 500000        # JIT optimization threshold

# Genetic query optimizer
geqo = on
geqo_threshold = 12
geqo_effort = 5
geqo_pool_size = 0
geqo_generations = 0
geqo_selection_bias = 2.0
geqo_seed = 0.0

# -----------------------------
# ERROR REPORTING AND LOGGING
# -----------------------------

# Logging configuration
log_destination = 'stderr'              # Log destination
logging_collector = on                  # Enable log collector
log_directory = 'log'                   # Log directory
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_file_mode = 0600
log_truncate_on_rotation = off
log_rotation_age = 1d                   # Rotate logs daily
log_rotation_size = 100MB               # Rotate when file reaches 100MB
log_min_messages = warning              # Minimum severity to log
log_min_error_statement = error         # Log statements causing errors
log_min_duration_statement = 1000       # Log slow queries (>1s)

# What to log
log_checkpoints = on                    # Log checkpoint activity
log_connections = off                   # Don't log connections (high volume)
log_disconnections = off                # Don't log disconnections
log_duration = off                      # Don't log statement duration
log_error_verbosity = default           # Error verbosity
log_hostname = off                      # Don't log hostname
log_line_prefix = '%m [%p] %q%u@%d '   # Log line prefix
log_lock_waits = on                     # Log lock waits
log_statement = 'none'                  # Log statements (none for performance)
log_replication_commands = off          # Log replication commands
log_temp_files = 10MB                   # Log temp files over 10MB
log_timezone = 'UTC'

# -----------------------------
# RUNTIME STATISTICS
# -----------------------------

# Statistics settings
track_activities = on                   # Track running queries
track_counts = on                       # Track table/index access
track_io_timing = on                    # Track I/O timing
track_functions = none                  # Don't track function calls
track_activity_query_size = 1024       # Query string size to track
stats_temp_directory = 'pg_stat_tmp'   # Temporary statistics directory

# -----------------------------
# AUTOVACUUM PARAMETERS
# -----------------------------

# Autovacuum settings (critical for performance)
autovacuum = on                         # Enable autovacuum
log_autovacuum_min_duration = 0         # Log all autovacuum activity
autovacuum_max_workers = 3              # Maximum autovacuum workers
autovacuum_naptime = 1min               # Sleep time between runs
autovacuum_vacuum_threshold = 50        # Minimum tuples before vacuum
autovacuum_analyze_threshold = 50       # Minimum tuples before analyze
autovacuum_vacuum_scale_factor = 0.2    # Fraction of table size for vacuum
autovacuum_analyze_scale_factor = 0.1   # Fraction of table size for analyze
autovacuum_freeze_max_age = 200000000   # Maximum XID age before vacuum
autovacuum_multixact_freeze_max_age = 400000000
autovacuum_vacuum_cost_delay = 2ms      # Vacuum cost delay
autovacuum_vacuum_cost_limit = 400      # Vacuum cost limit

# -----------------------------
# CLIENT CONNECTION DEFAULTS
# -----------------------------

# Statement behavior
search_path = '"$user", public'        # Schema search path
default_tablespace = ''                # Default tablespace
temp_tablespaces = ''                  # Temporary tablespaces
check_function_bodies = on             # Check function bodies
default_transaction_isolation = 'read committed'
default_transaction_read_only = off
default_transaction_deferrable = off
session_replication_role = 'origin'

# Statement timeout and locks
statement_timeout = 0                   # No statement timeout by default
lock_timeout = 0                       # No lock timeout by default
idle_in_transaction_session_timeout = 0 # No idle timeout by default
vacuum_freeze_min_age = 50000000       # Minimum age for freezing
vacuum_freeze_table_age = 150000000    # Age at which to scan whole table
vacuum_multixact_freeze_min_age = 5000000
vacuum_multixact_freeze_table_age = 150000000

# Locale and formatting
datestyle = 'iso, mdy'
intervalstyle = 'postgres'
timezone = 'UTC'
timezone_abbreviations = 'Default'
extra_float_digits = 1
client_encoding = sql_ascii

# Shared library preloading
shared_preload_libraries = 'pg_stat_statements'

# -----------------------------
# PERFORMANCE EXTENSIONS
# -----------------------------

# pg_stat_statements configuration
pg_stat_statements.max = 10000          # Number of statements tracked
pg_stat_statements.track = all          # Track all statements
pg_stat_statements.track_utility = off  # Don't track utility commands
pg_stat_statements.save = on            # Save statistics across restarts

# -----------------------------
# CUSTOM PERFORMANCE SETTINGS
# -----------------------------

# Application-specific optimizations
max_pred_locks_per_transaction = 64
max_pred_locks_per_relation = -2
max_pred_locks_per_page = 2

# JIT compilation (PostgreSQL 11+)
jit = on                               # Enable JIT compilation
jit_provider = 'llvmjit'              # JIT provider

# Parallel query settings
force_parallel_mode = off              # Don't force parallel mode
parallel_leader_participation = on     # Leader participates in parallel query

# Background writer tuning for high write workloads
checkpoint_segments = 32               # WAL segments between checkpoints (older versions)
wal_keep_segments = 64                 # WAL segments to keep (older versions)

# For PostgreSQL 13+ (WAL management)
# wal_keep_size = 1GB                  # Amount of WAL to keep
# max_slot_wal_keep_size = 1GB         # Maximum WAL kept by replication slots

# Connection pooling optimization (when using connection pooler)
# These settings work well with pgbouncer
# max_connections = 20                 # Lower when using connection pooler
# shared_buffers = 512MB               # Can be higher with fewer connections

# -----------------------------
# MONITORING AND ALERTING
# -----------------------------

# Enable additional monitoring
log_parser_stats = off
log_planner_stats = off
log_executor_stats = off
log_statement_stats = off

# Track wait events (PostgreSQL 9.6+)
# track_wait_events = on

# Custom settings for application monitoring
application_name = 'selextract-cloud'

# -----------------------------
# SECURITY SETTINGS
# -----------------------------

# SSL configuration
ssl_cert_file = 'server.crt'
ssl_key_file = 'server.key'
ssl_ca_file = ''
ssl_crl_file = ''

# Authentication
password_encryption = scram-sha-256
krb_server_keyfile = ''
krb_caseins_users = off
db_user_namespace = off

# Row security
row_security = on

# -----------------------------
# ERROR HANDLING
# -----------------------------

exit_on_error = off
restart_after_crash = on
data_sync_retry = off

# -----------------------------
# VACUUM AND ANALYZE SETTINGS
# -----------------------------

# Vacuum settings for heavy write workloads
vacuum_cost_delay = 0                  # No delay for vacuum
vacuum_cost_page_hit = 1               # Cost for buffer hit
vacuum_cost_page_miss = 10             # Cost for buffer miss
vacuum_cost_page_dirty = 20            # Cost for dirty page
vacuum_cost_limit = 200               # Vacuum cost limit

# Analyze settings
default_statistics_target = 100        # Statistics target for analyze

# -----------------------------
# CUSTOM APPLICATION SETTINGS
# -----------------------------

# Settings specific to Selextract Cloud workload patterns

# For high-frequency INSERT/UPDATE workloads (tasks table)
# Consider partitioning large tables by date
# PARTITION BY RANGE (created_at)

# For analytics queries (reporting)
# Consider materialized views for complex aggregations
# REFRESH MATERIALIZED VIEW CONCURRENTLY

# Connection pooling recommendations:
# Use pgbouncer with pool_mode = transaction
# Set max_client_conn = 1000 in pgbouncer
# Set default_pool_size = 20 in pgbouncer